{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import detectron2\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "\n",
    "import numpy as np\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "TRAINJSON = \"./dataset/train.json\"\n",
    "TESTJSON = \"./dataset/test.json\"\n",
    "IMAGEROOT = \"./dataset/\"\n",
    "\n",
    "TRAIN_DATASET_NAME = 'coco_trash_train'\n",
    "TEST_DATASET_NAME = 'coco_trash_test'\n",
    "\n",
    "TARGETCLASSES = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]\n",
    "\n",
    "MODELZOO_CONFIGNAME = 'COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml'\n",
    "\n",
    "NUM_WORKERS = 4\n",
    "IMS_PER_BATCH = 4\n",
    "BASE_LR = 0.001\n",
    "MAX_ITER = 15000\n",
    "STEPS = (8000,12000)\n",
    "GAMMA = 0.005\n",
    "CHECKPOINT_PERIOD = 3000\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "OUTPUT_DIR = \"./output\"\n",
    "\n",
    "ROI_BATCH = 128\n",
    "ROI_NUM_CLASSES = len(TARGETCLASSES)\n",
    "\n",
    "TEST_EVAL_PERIOD = 3000\n",
    "\n",
    "print(len(TARGETCLASSES))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def setSeed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(f\">> Seed : {seed}\")\n",
    "setSeed(SEED)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">> Seed : 42\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Register Dataset\n",
    "try:\n",
    "    register_coco_instances(TRAIN_DATASET_NAME, {}, TRAINJSON, IMAGEROOT)\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    register_coco_instances(TEST_DATASET_NAME, {}, TESTJSON, IMAGEROOT)\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "MetadataCatalog.get(TRAIN_DATASET_NAME).thing_classes = TARGETCLASSES"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# config 불러오기\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(MODELZOO_CONFIGNAME))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# config 수정하기\n",
    "cfg.DATASETS.TRAIN = (TRAIN_DATASET_NAME,)\n",
    "cfg.DATASETS.TEST = (TEST_DATASET_NAME,)\n",
    "\n",
    "cfg.DATALOADER.NUM_WOREKRS = NUM_WORKERS\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(MODELZOO_CONFIGNAME)\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = IMS_PER_BATCH\n",
    "cfg.SOLVER.BASE_LR = BASE_LR\n",
    "cfg.SOLVER.MAX_ITER = MAX_ITER\n",
    "cfg.SOLVER.STEPS = STEPS\n",
    "cfg.SOLVER.GAMMA = GAMMA\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = CHECKPOINT_PERIOD\n",
    "\n",
    "cfg.OUTPUT_DIR = OUTPUT_DIR\n",
    "\n",
    "# cfg.SEED = SEED\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = ROI_BATCH\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES =ROI_NUM_CLASSES\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = TEST_EVAL_PERIOD"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# mapper - input data를 어떤 형식으로 return할지 (따라서 augmnentation 등 데이터 전처리 포함 됨)\n",
    "import detectron2.data.transforms as T\n",
    "\n",
    "def MyMapper(dataset_dict):\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    image = utils.read_image(dataset_dict['file_name'], format='BGR')\n",
    "    \n",
    "    transform_list = [\n",
    "        T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "        T.RandomBrightness(0.8, 1.8),\n",
    "        T.RandomContrast(0.6, 1.3)\n",
    "    ]\n",
    "    \n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    \n",
    "    dataset_dict['image'] = torch.as_tensor(image.transpose(2,0,1).astype('float32'))\n",
    "    \n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop('annotations')\n",
    "        if obj.get('iscrowd', 0) == 0\n",
    "    ]\n",
    "    \n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict['instances'] = utils.filter_empty_instances(instances)\n",
    "    \n",
    "    return dataset_dict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# trainer - DefaultTrainer를 상속\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg, sampler=None):\n",
    "        return build_detection_train_loader(\n",
    "        cfg, mapper = MyMapper, sampler = sampler\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs('./output_eval', exist_ok = True)\n",
    "            output_folder = './output_eval'\n",
    "            \n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# train\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok = True)\n",
    "\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[32m[09/29 04:52:05 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=11, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[09/29 04:52:05 d2.data.datasets.coco]: \u001b[0mLoaded 4883 images in COCO format from ./dataset/train.json\n",
      "\u001b[32m[09/29 04:52:06 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 4883 images left.\n",
      "\u001b[32m[09/29 04:52:06 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "| General trash | 3966         |    Paper    | 6352         | Paper pack | 897          |\n",
      "|     Metal     | 936          |    Glass    | 982          |  Plastic   | 2943         |\n",
      "|   Styrofoam   | 1263         | Plastic bag | 5178         |  Battery   | 159          |\n",
      "|   Clothing    | 468          |             |              |            |              |\n",
      "|     total     | 23144        |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[09/29 04:52:06 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[09/29 04:52:06 d2.data.common]: \u001b[0mSerializing 4883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/29 04:52:06 d2.data.common]: \u001b[0mSerialized dataset takes 2.17 MiB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (11, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (40, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (40,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[32m[09/29 04:52:06 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/ml/detection/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:103: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370172916/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  num_fg = fg_inds.nonzero().numel()\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[32m[09/29 04:52:23 d2.utils.events]: \u001b[0m eta: 2:12:03  iter: 19  total_loss: 3.325  loss_cls: 2.439  loss_box_reg: 0.6966  loss_rpn_cls: 0.1062  loss_rpn_loc: 0.04659  time: 0.5304  data_time: 0.0323  lr: 1.9981e-05  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:52:33 d2.utils.events]: \u001b[0m eta: 2:11:43  iter: 39  total_loss: 2.783  loss_cls: 1.986  loss_box_reg: 0.688  loss_rpn_cls: 0.0424  loss_rpn_loc: 0.02551  time: 0.5290  data_time: 0.0139  lr: 3.9961e-05  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:52:44 d2.utils.events]: \u001b[0m eta: 2:11:30  iter: 59  total_loss: 2.052  loss_cls: 1.198  loss_box_reg: 0.747  loss_rpn_cls: 0.04386  loss_rpn_loc: 0.02164  time: 0.5287  data_time: 0.0139  lr: 5.9941e-05  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:52:55 d2.utils.events]: \u001b[0m eta: 2:11:20  iter: 79  total_loss: 1.611  loss_cls: 0.8115  loss_box_reg: 0.6789  loss_rpn_cls: 0.07383  loss_rpn_loc: 0.03665  time: 0.5286  data_time: 0.0140  lr: 7.9921e-05  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:53:05 d2.utils.events]: \u001b[0m eta: 2:11:16  iter: 99  total_loss: 1.726  loss_cls: 0.8086  loss_box_reg: 0.7639  loss_rpn_cls: 0.06944  loss_rpn_loc: 0.03241  time: 0.5293  data_time: 0.0142  lr: 9.9901e-05  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:53:16 d2.utils.events]: \u001b[0m eta: 2:11:05  iter: 119  total_loss: 1.454  loss_cls: 0.6655  loss_box_reg: 0.6617  loss_rpn_cls: 0.02996  loss_rpn_loc: 0.02791  time: 0.5297  data_time: 0.0142  lr: 0.00011988  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:53:27 d2.utils.events]: \u001b[0m eta: 2:10:54  iter: 139  total_loss: 1.456  loss_cls: 0.6852  loss_box_reg: 0.7049  loss_rpn_cls: 0.03219  loss_rpn_loc: 0.01856  time: 0.5295  data_time: 0.0142  lr: 0.00013986  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:53:37 d2.utils.events]: \u001b[0m eta: 2:10:44  iter: 159  total_loss: 1.387  loss_cls: 0.649  loss_box_reg: 0.6908  loss_rpn_cls: 0.01508  loss_rpn_loc: 0.01812  time: 0.5294  data_time: 0.0146  lr: 0.00015984  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:53:48 d2.utils.events]: \u001b[0m eta: 2:10:34  iter: 179  total_loss: 1.61  loss_cls: 0.6846  loss_box_reg: 0.7475  loss_rpn_cls: 0.04916  loss_rpn_loc: 0.03306  time: 0.5295  data_time: 0.0148  lr: 0.00017982  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:53:58 d2.utils.events]: \u001b[0m eta: 2:10:26  iter: 199  total_loss: 1.597  loss_cls: 0.734  loss_box_reg: 0.7515  loss_rpn_cls: 0.04811  loss_rpn_loc: 0.03982  time: 0.5297  data_time: 0.0142  lr: 0.0001998  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:54:09 d2.utils.events]: \u001b[0m eta: 2:10:19  iter: 219  total_loss: 1.501  loss_cls: 0.6498  loss_box_reg: 0.7745  loss_rpn_cls: 0.03349  loss_rpn_loc: 0.01438  time: 0.5299  data_time: 0.0142  lr: 0.00021978  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:54:20 d2.utils.events]: \u001b[0m eta: 2:10:10  iter: 239  total_loss: 1.562  loss_cls: 0.7087  loss_box_reg: 0.7177  loss_rpn_cls: 0.03542  loss_rpn_loc: 0.03205  time: 0.5300  data_time: 0.0149  lr: 0.00023976  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:54:30 d2.utils.events]: \u001b[0m eta: 2:10:02  iter: 259  total_loss: 1.363  loss_cls: 0.6085  loss_box_reg: 0.6887  loss_rpn_cls: 0.01914  loss_rpn_loc: 0.02125  time: 0.5301  data_time: 0.0144  lr: 0.00025974  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:54:41 d2.utils.events]: \u001b[0m eta: 2:09:53  iter: 279  total_loss: 1.247  loss_cls: 0.5788  loss_box_reg: 0.6454  loss_rpn_cls: 0.01904  loss_rpn_loc: 0.03316  time: 0.5301  data_time: 0.0145  lr: 0.00027972  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:54:52 d2.utils.events]: \u001b[0m eta: 2:09:43  iter: 299  total_loss: 1.419  loss_cls: 0.6201  loss_box_reg: 0.6725  loss_rpn_cls: 0.02928  loss_rpn_loc: 0.0288  time: 0.5303  data_time: 0.0150  lr: 0.0002997  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:55:02 d2.utils.events]: \u001b[0m eta: 2:09:34  iter: 319  total_loss: 1.255  loss_cls: 0.5853  loss_box_reg: 0.6387  loss_rpn_cls: 0.02682  loss_rpn_loc: 0.01669  time: 0.5306  data_time: 0.0159  lr: 0.00031968  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:55:13 d2.utils.events]: \u001b[0m eta: 2:09:26  iter: 339  total_loss: 1.175  loss_cls: 0.5702  loss_box_reg: 0.5489  loss_rpn_cls: 0.02207  loss_rpn_loc: 0.02444  time: 0.5311  data_time: 0.0163  lr: 0.00033966  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:55:24 d2.utils.events]: \u001b[0m eta: 2:09:16  iter: 359  total_loss: 1.301  loss_cls: 0.6028  loss_box_reg: 0.5535  loss_rpn_cls: 0.03655  loss_rpn_loc: 0.0411  time: 0.5312  data_time: 0.0153  lr: 0.00035964  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:55:34 d2.utils.events]: \u001b[0m eta: 2:09:06  iter: 379  total_loss: 1.125  loss_cls: 0.5301  loss_box_reg: 0.4996  loss_rpn_cls: 0.0343  loss_rpn_loc: 0.04524  time: 0.5312  data_time: 0.0143  lr: 0.00037962  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:55:45 d2.utils.events]: \u001b[0m eta: 2:08:56  iter: 399  total_loss: 1.041  loss_cls: 0.5358  loss_box_reg: 0.4604  loss_rpn_cls: 0.03294  loss_rpn_loc: 0.02938  time: 0.5312  data_time: 0.0145  lr: 0.0003996  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:55:56 d2.utils.events]: \u001b[0m eta: 2:08:46  iter: 419  total_loss: 1.077  loss_cls: 0.5378  loss_box_reg: 0.4305  loss_rpn_cls: 0.03132  loss_rpn_loc: 0.0245  time: 0.5312  data_time: 0.0153  lr: 0.00041958  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:56:06 d2.utils.events]: \u001b[0m eta: 2:08:36  iter: 439  total_loss: 0.9726  loss_cls: 0.5189  loss_box_reg: 0.3932  loss_rpn_cls: 0.02321  loss_rpn_loc: 0.02202  time: 0.5313  data_time: 0.0148  lr: 0.00043956  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:56:17 d2.utils.events]: \u001b[0m eta: 2:08:25  iter: 459  total_loss: 1.155  loss_cls: 0.5805  loss_box_reg: 0.4428  loss_rpn_cls: 0.03587  loss_rpn_loc: 0.0381  time: 0.5313  data_time: 0.0151  lr: 0.00045954  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:56:28 d2.utils.events]: \u001b[0m eta: 2:08:15  iter: 479  total_loss: 0.944  loss_cls: 0.516  loss_box_reg: 0.3454  loss_rpn_cls: 0.02408  loss_rpn_loc: 0.02848  time: 0.5315  data_time: 0.0173  lr: 0.00047952  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:56:38 d2.utils.events]: \u001b[0m eta: 2:08:04  iter: 499  total_loss: 0.9675  loss_cls: 0.5163  loss_box_reg: 0.3934  loss_rpn_cls: 0.03614  loss_rpn_loc: 0.03012  time: 0.5315  data_time: 0.0161  lr: 0.0004995  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:56:49 d2.utils.events]: \u001b[0m eta: 2:07:53  iter: 519  total_loss: 1.023  loss_cls: 0.546  loss_box_reg: 0.3886  loss_rpn_cls: 0.03597  loss_rpn_loc: 0.026  time: 0.5314  data_time: 0.0148  lr: 0.00051948  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:57:00 d2.utils.events]: \u001b[0m eta: 2:07:42  iter: 539  total_loss: 0.9547  loss_cls: 0.5532  loss_box_reg: 0.3534  loss_rpn_cls: 0.03889  loss_rpn_loc: 0.01898  time: 0.5314  data_time: 0.0151  lr: 0.00053946  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:57:10 d2.utils.events]: \u001b[0m eta: 2:07:32  iter: 559  total_loss: 0.8948  loss_cls: 0.5044  loss_box_reg: 0.3513  loss_rpn_cls: 0.02575  loss_rpn_loc: 0.03327  time: 0.5314  data_time: 0.0156  lr: 0.00055944  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:57:21 d2.utils.events]: \u001b[0m eta: 2:07:21  iter: 579  total_loss: 0.8722  loss_cls: 0.4721  loss_box_reg: 0.3292  loss_rpn_cls: 0.02476  loss_rpn_loc: 0.02278  time: 0.5315  data_time: 0.0162  lr: 0.00057942  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:57:32 d2.utils.events]: \u001b[0m eta: 2:07:11  iter: 599  total_loss: 0.9415  loss_cls: 0.5257  loss_box_reg: 0.3458  loss_rpn_cls: 0.0308  loss_rpn_loc: 0.03059  time: 0.5315  data_time: 0.0156  lr: 0.0005994  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:57:42 d2.utils.events]: \u001b[0m eta: 2:07:01  iter: 619  total_loss: 0.8143  loss_cls: 0.4654  loss_box_reg: 0.347  loss_rpn_cls: 0.02227  loss_rpn_loc: 0.02286  time: 0.5316  data_time: 0.0166  lr: 0.00061938  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:57:53 d2.utils.events]: \u001b[0m eta: 2:06:52  iter: 639  total_loss: 0.9128  loss_cls: 0.5241  loss_box_reg: 0.3335  loss_rpn_cls: 0.02345  loss_rpn_loc: 0.02164  time: 0.5316  data_time: 0.0158  lr: 0.00063936  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:58:04 d2.utils.events]: \u001b[0m eta: 2:06:41  iter: 659  total_loss: 0.8699  loss_cls: 0.5004  loss_box_reg: 0.3525  loss_rpn_cls: 0.02295  loss_rpn_loc: 0.01916  time: 0.5316  data_time: 0.0149  lr: 0.00065934  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:58:14 d2.utils.events]: \u001b[0m eta: 2:06:30  iter: 679  total_loss: 0.9419  loss_cls: 0.4994  loss_box_reg: 0.3523  loss_rpn_cls: 0.03969  loss_rpn_loc: 0.03927  time: 0.5317  data_time: 0.0178  lr: 0.00067932  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:58:25 d2.utils.events]: \u001b[0m eta: 2:06:19  iter: 699  total_loss: 0.9912  loss_cls: 0.5208  loss_box_reg: 0.3792  loss_rpn_cls: 0.03149  loss_rpn_loc: 0.02973  time: 0.5317  data_time: 0.0147  lr: 0.0006993  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:58:36 d2.utils.events]: \u001b[0m eta: 2:06:08  iter: 719  total_loss: 0.9547  loss_cls: 0.489  loss_box_reg: 0.3373  loss_rpn_cls: 0.0281  loss_rpn_loc: 0.02799  time: 0.5317  data_time: 0.0155  lr: 0.00071928  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:58:46 d2.utils.events]: \u001b[0m eta: 2:05:58  iter: 739  total_loss: 0.997  loss_cls: 0.543  loss_box_reg: 0.388  loss_rpn_cls: 0.04273  loss_rpn_loc: 0.03286  time: 0.5317  data_time: 0.0165  lr: 0.00073926  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:58:57 d2.utils.events]: \u001b[0m eta: 2:05:47  iter: 759  total_loss: 0.8442  loss_cls: 0.424  loss_box_reg: 0.324  loss_rpn_cls: 0.02795  loss_rpn_loc: 0.02667  time: 0.5317  data_time: 0.0152  lr: 0.00075924  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:59:08 d2.utils.events]: \u001b[0m eta: 2:05:36  iter: 779  total_loss: 0.9615  loss_cls: 0.5319  loss_box_reg: 0.3653  loss_rpn_cls: 0.03159  loss_rpn_loc: 0.02568  time: 0.5317  data_time: 0.0150  lr: 0.00077922  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:59:18 d2.utils.events]: \u001b[0m eta: 2:05:26  iter: 799  total_loss: 0.8817  loss_cls: 0.4735  loss_box_reg: 0.3378  loss_rpn_cls: 0.0296  loss_rpn_loc: 0.03077  time: 0.5317  data_time: 0.0150  lr: 0.0007992  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:59:29 d2.utils.events]: \u001b[0m eta: 2:05:16  iter: 819  total_loss: 0.7423  loss_cls: 0.4519  loss_box_reg: 0.2744  loss_rpn_cls: 0.01981  loss_rpn_loc: 0.01841  time: 0.5317  data_time: 0.0147  lr: 0.00081918  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:59:39 d2.utils.events]: \u001b[0m eta: 2:05:06  iter: 839  total_loss: 0.8992  loss_cls: 0.5386  loss_box_reg: 0.3153  loss_rpn_cls: 0.03777  loss_rpn_loc: 0.0299  time: 0.5317  data_time: 0.0148  lr: 0.00083916  max_mem: 20741M\n",
      "\u001b[32m[09/29 04:59:50 d2.utils.events]: \u001b[0m eta: 2:04:56  iter: 859  total_loss: 0.8575  loss_cls: 0.4683  loss_box_reg: 0.3288  loss_rpn_cls: 0.02958  loss_rpn_loc: 0.02118  time: 0.5317  data_time: 0.0160  lr: 0.00085914  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:00:01 d2.utils.events]: \u001b[0m eta: 2:04:46  iter: 879  total_loss: 0.9187  loss_cls: 0.5276  loss_box_reg: 0.3112  loss_rpn_cls: 0.02962  loss_rpn_loc: 0.0436  time: 0.5317  data_time: 0.0159  lr: 0.00087912  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:00:11 d2.utils.events]: \u001b[0m eta: 2:04:35  iter: 899  total_loss: 0.9823  loss_cls: 0.5072  loss_box_reg: 0.3505  loss_rpn_cls: 0.04435  loss_rpn_loc: 0.03255  time: 0.5317  data_time: 0.0160  lr: 0.0008991  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:00:22 d2.utils.events]: \u001b[0m eta: 2:04:24  iter: 919  total_loss: 0.8413  loss_cls: 0.4561  loss_box_reg: 0.3121  loss_rpn_cls: 0.02642  loss_rpn_loc: 0.04301  time: 0.5317  data_time: 0.0165  lr: 0.00091908  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:00:33 d2.utils.events]: \u001b[0m eta: 2:04:14  iter: 939  total_loss: 0.7291  loss_cls: 0.4192  loss_box_reg: 0.2625  loss_rpn_cls: 0.02223  loss_rpn_loc: 0.02087  time: 0.5317  data_time: 0.0163  lr: 0.00093906  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:00:43 d2.utils.events]: \u001b[0m eta: 2:04:03  iter: 959  total_loss: 0.7442  loss_cls: 0.4261  loss_box_reg: 0.279  loss_rpn_cls: 0.01427  loss_rpn_loc: 0.01737  time: 0.5316  data_time: 0.0147  lr: 0.00095904  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:00:54 d2.utils.events]: \u001b[0m eta: 2:03:51  iter: 979  total_loss: 0.7856  loss_cls: 0.442  loss_box_reg: 0.301  loss_rpn_cls: 0.02983  loss_rpn_loc: 0.02439  time: 0.5315  data_time: 0.0147  lr: 0.00097902  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:01:05 d2.utils.events]: \u001b[0m eta: 2:03:41  iter: 999  total_loss: 0.9064  loss_cls: 0.5341  loss_box_reg: 0.323  loss_rpn_cls: 0.0314  loss_rpn_loc: 0.0237  time: 0.5315  data_time: 0.0149  lr: 0.000999  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:01:15 d2.utils.events]: \u001b[0m eta: 2:03:30  iter: 1019  total_loss: 0.9265  loss_cls: 0.5133  loss_box_reg: 0.35  loss_rpn_cls: 0.02991  loss_rpn_loc: 0.03507  time: 0.5315  data_time: 0.0164  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:01:26 d2.utils.events]: \u001b[0m eta: 2:03:20  iter: 1039  total_loss: 0.8503  loss_cls: 0.4606  loss_box_reg: 0.3071  loss_rpn_cls: 0.02866  loss_rpn_loc: 0.0341  time: 0.5315  data_time: 0.0161  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:01:37 d2.utils.events]: \u001b[0m eta: 2:03:11  iter: 1059  total_loss: 0.7878  loss_cls: 0.4183  loss_box_reg: 0.2927  loss_rpn_cls: 0.02704  loss_rpn_loc: 0.02678  time: 0.5316  data_time: 0.0162  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:01:47 d2.utils.events]: \u001b[0m eta: 2:03:00  iter: 1079  total_loss: 0.8076  loss_cls: 0.4543  loss_box_reg: 0.3201  loss_rpn_cls: 0.02227  loss_rpn_loc: 0.02971  time: 0.5316  data_time: 0.0149  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:01:58 d2.utils.events]: \u001b[0m eta: 2:02:50  iter: 1099  total_loss: 0.8355  loss_cls: 0.4181  loss_box_reg: 0.2941  loss_rpn_cls: 0.02197  loss_rpn_loc: 0.01588  time: 0.5316  data_time: 0.0147  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:02:09 d2.utils.events]: \u001b[0m eta: 2:02:40  iter: 1119  total_loss: 0.9067  loss_cls: 0.4497  loss_box_reg: 0.3313  loss_rpn_cls: 0.04114  loss_rpn_loc: 0.04666  time: 0.5318  data_time: 0.0156  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:02:19 d2.utils.events]: \u001b[0m eta: 2:02:30  iter: 1139  total_loss: 0.8723  loss_cls: 0.4423  loss_box_reg: 0.3674  loss_rpn_cls: 0.03516  loss_rpn_loc: 0.03827  time: 0.5318  data_time: 0.0151  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:02:30 d2.utils.events]: \u001b[0m eta: 2:02:20  iter: 1159  total_loss: 0.9772  loss_cls: 0.5427  loss_box_reg: 0.3528  loss_rpn_cls: 0.02964  loss_rpn_loc: 0.03222  time: 0.5318  data_time: 0.0156  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:02:41 d2.utils.events]: \u001b[0m eta: 2:02:09  iter: 1179  total_loss: 0.7907  loss_cls: 0.4015  loss_box_reg: 0.287  loss_rpn_cls: 0.04031  loss_rpn_loc: 0.02667  time: 0.5318  data_time: 0.0148  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:02:51 d2.utils.events]: \u001b[0m eta: 2:01:59  iter: 1199  total_loss: 0.8884  loss_cls: 0.4478  loss_box_reg: 0.289  loss_rpn_cls: 0.02812  loss_rpn_loc: 0.03562  time: 0.5318  data_time: 0.0149  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:03:02 d2.utils.events]: \u001b[0m eta: 2:01:47  iter: 1219  total_loss: 0.7439  loss_cls: 0.3719  loss_box_reg: 0.2727  loss_rpn_cls: 0.01644  loss_rpn_loc: 0.01379  time: 0.5317  data_time: 0.0148  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:03:13 d2.utils.events]: \u001b[0m eta: 2:01:36  iter: 1239  total_loss: 0.8668  loss_cls: 0.4553  loss_box_reg: 0.3273  loss_rpn_cls: 0.02438  loss_rpn_loc: 0.02735  time: 0.5317  data_time: 0.0148  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:03:23 d2.utils.events]: \u001b[0m eta: 2:01:25  iter: 1259  total_loss: 0.8671  loss_cls: 0.4631  loss_box_reg: 0.3328  loss_rpn_cls: 0.01553  loss_rpn_loc: 0.02348  time: 0.5316  data_time: 0.0147  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:03:34 d2.utils.events]: \u001b[0m eta: 2:01:14  iter: 1279  total_loss: 0.8411  loss_cls: 0.4629  loss_box_reg: 0.2928  loss_rpn_cls: 0.02303  loss_rpn_loc: 0.02273  time: 0.5316  data_time: 0.0150  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:03:44 d2.utils.events]: \u001b[0m eta: 2:01:04  iter: 1299  total_loss: 0.9048  loss_cls: 0.4536  loss_box_reg: 0.326  loss_rpn_cls: 0.03478  loss_rpn_loc: 0.02914  time: 0.5317  data_time: 0.0161  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:03:55 d2.utils.events]: \u001b[0m eta: 2:00:53  iter: 1319  total_loss: 0.8093  loss_cls: 0.4573  loss_box_reg: 0.3023  loss_rpn_cls: 0.02941  loss_rpn_loc: 0.02997  time: 0.5318  data_time: 0.0154  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:04:06 d2.utils.events]: \u001b[0m eta: 2:00:43  iter: 1339  total_loss: 0.7228  loss_cls: 0.4193  loss_box_reg: 0.271  loss_rpn_cls: 0.01713  loss_rpn_loc: 0.0115  time: 0.5318  data_time: 0.0163  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:04:17 d2.utils.events]: \u001b[0m eta: 2:00:32  iter: 1359  total_loss: 0.9212  loss_cls: 0.488  loss_box_reg: 0.3486  loss_rpn_cls: 0.02224  loss_rpn_loc: 0.03098  time: 0.5318  data_time: 0.0150  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:04:27 d2.utils.events]: \u001b[0m eta: 2:00:21  iter: 1379  total_loss: 0.8078  loss_cls: 0.4256  loss_box_reg: 0.326  loss_rpn_cls: 0.02829  loss_rpn_loc: 0.03669  time: 0.5318  data_time: 0.0161  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:04:38 d2.utils.events]: \u001b[0m eta: 2:00:11  iter: 1399  total_loss: 0.8328  loss_cls: 0.4601  loss_box_reg: 0.3164  loss_rpn_cls: 0.01619  loss_rpn_loc: 0.02326  time: 0.5318  data_time: 0.0165  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:04:49 d2.utils.events]: \u001b[0m eta: 2:00:00  iter: 1419  total_loss: 0.7433  loss_cls: 0.4331  loss_box_reg: 0.2898  loss_rpn_cls: 0.03017  loss_rpn_loc: 0.01936  time: 0.5318  data_time: 0.0151  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:04:59 d2.utils.events]: \u001b[0m eta: 1:59:49  iter: 1439  total_loss: 0.6771  loss_cls: 0.407  loss_box_reg: 0.2514  loss_rpn_cls: 0.02033  loss_rpn_loc: 0.01459  time: 0.5319  data_time: 0.0194  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:05:10 d2.utils.events]: \u001b[0m eta: 1:59:39  iter: 1459  total_loss: 0.9511  loss_cls: 0.491  loss_box_reg: 0.3312  loss_rpn_cls: 0.02844  loss_rpn_loc: 0.04281  time: 0.5320  data_time: 0.0167  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:05:21 d2.utils.events]: \u001b[0m eta: 1:59:28  iter: 1479  total_loss: 0.8469  loss_cls: 0.5118  loss_box_reg: 0.2979  loss_rpn_cls: 0.02646  loss_rpn_loc: 0.0316  time: 0.5319  data_time: 0.0149  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:05:31 d2.utils.events]: \u001b[0m eta: 1:59:19  iter: 1499  total_loss: 0.7898  loss_cls: 0.4436  loss_box_reg: 0.277  loss_rpn_cls: 0.01823  loss_rpn_loc: 0.01658  time: 0.5320  data_time: 0.0171  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:05:42 d2.utils.events]: \u001b[0m eta: 1:59:09  iter: 1519  total_loss: 0.7534  loss_cls: 0.4543  loss_box_reg: 0.2747  loss_rpn_cls: 0.01803  loss_rpn_loc: 0.02923  time: 0.5320  data_time: 0.0150  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:05:53 d2.utils.events]: \u001b[0m eta: 1:58:58  iter: 1539  total_loss: 0.8165  loss_cls: 0.4791  loss_box_reg: 0.292  loss_rpn_cls: 0.0204  loss_rpn_loc: 0.03196  time: 0.5320  data_time: 0.0149  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:06:03 d2.utils.events]: \u001b[0m eta: 1:58:47  iter: 1559  total_loss: 0.7532  loss_cls: 0.4331  loss_box_reg: 0.2965  loss_rpn_cls: 0.01537  loss_rpn_loc: 0.01919  time: 0.5320  data_time: 0.0149  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:06:14 d2.utils.events]: \u001b[0m eta: 1:58:37  iter: 1579  total_loss: 0.7793  loss_cls: 0.4295  loss_box_reg: 0.3144  loss_rpn_cls: 0.01646  loss_rpn_loc: 0.02766  time: 0.5320  data_time: 0.0152  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:06:25 d2.utils.events]: \u001b[0m eta: 1:58:26  iter: 1599  total_loss: 0.8179  loss_cls: 0.4122  loss_box_reg: 0.3117  loss_rpn_cls: 0.02807  loss_rpn_loc: 0.0251  time: 0.5319  data_time: 0.0147  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:06:35 d2.utils.events]: \u001b[0m eta: 1:58:14  iter: 1619  total_loss: 0.8021  loss_cls: 0.4093  loss_box_reg: 0.3148  loss_rpn_cls: 0.02956  loss_rpn_loc: 0.03156  time: 0.5319  data_time: 0.0147  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:06:46 d2.utils.events]: \u001b[0m eta: 1:58:03  iter: 1639  total_loss: 0.7426  loss_cls: 0.442  loss_box_reg: 0.2656  loss_rpn_cls: 0.01758  loss_rpn_loc: 0.01528  time: 0.5319  data_time: 0.0148  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:06:56 d2.utils.events]: \u001b[0m eta: 1:57:52  iter: 1659  total_loss: 0.7853  loss_cls: 0.4225  loss_box_reg: 0.282  loss_rpn_cls: 0.02209  loss_rpn_loc: 0.03127  time: 0.5318  data_time: 0.0146  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:07:07 d2.utils.events]: \u001b[0m eta: 1:57:41  iter: 1679  total_loss: 0.7812  loss_cls: 0.4255  loss_box_reg: 0.3156  loss_rpn_cls: 0.02206  loss_rpn_loc: 0.02389  time: 0.5318  data_time: 0.0154  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:07:18 d2.utils.events]: \u001b[0m eta: 1:57:31  iter: 1699  total_loss: 0.7299  loss_cls: 0.4018  loss_box_reg: 0.2494  loss_rpn_cls: 0.01976  loss_rpn_loc: 0.02461  time: 0.5319  data_time: 0.0176  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:07:29 d2.utils.events]: \u001b[0m eta: 1:57:21  iter: 1719  total_loss: 0.7661  loss_cls: 0.4079  loss_box_reg: 0.2599  loss_rpn_cls: 0.02321  loss_rpn_loc: 0.02488  time: 0.5320  data_time: 0.0149  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:07:39 d2.utils.events]: \u001b[0m eta: 1:57:10  iter: 1739  total_loss: 0.738  loss_cls: 0.4116  loss_box_reg: 0.2928  loss_rpn_cls: 0.01772  loss_rpn_loc: 0.02447  time: 0.5320  data_time: 0.0147  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:07:50 d2.utils.events]: \u001b[0m eta: 1:57:00  iter: 1759  total_loss: 0.7293  loss_cls: 0.4297  loss_box_reg: 0.236  loss_rpn_cls: 0.01482  loss_rpn_loc: 0.01964  time: 0.5319  data_time: 0.0146  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:08:00 d2.utils.events]: \u001b[0m eta: 1:56:49  iter: 1779  total_loss: 0.8323  loss_cls: 0.4687  loss_box_reg: 0.2772  loss_rpn_cls: 0.02544  loss_rpn_loc: 0.02648  time: 0.5319  data_time: 0.0147  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:08:11 d2.utils.events]: \u001b[0m eta: 1:56:38  iter: 1799  total_loss: 0.7506  loss_cls: 0.4221  loss_box_reg: 0.2909  loss_rpn_cls: 0.01412  loss_rpn_loc: 0.02113  time: 0.5319  data_time: 0.0144  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:08:22 d2.utils.events]: \u001b[0m eta: 1:56:26  iter: 1819  total_loss: 0.7843  loss_cls: 0.4917  loss_box_reg: 0.2445  loss_rpn_cls: 0.0291  loss_rpn_loc: 0.02433  time: 0.5319  data_time: 0.0160  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:08:32 d2.utils.events]: \u001b[0m eta: 1:56:15  iter: 1839  total_loss: 0.7288  loss_cls: 0.388  loss_box_reg: 0.2552  loss_rpn_cls: 0.01853  loss_rpn_loc: 0.03076  time: 0.5318  data_time: 0.0146  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:08:43 d2.utils.events]: \u001b[0m eta: 1:56:04  iter: 1859  total_loss: 0.7735  loss_cls: 0.4106  loss_box_reg: 0.2737  loss_rpn_cls: 0.01892  loss_rpn_loc: 0.02258  time: 0.5319  data_time: 0.0148  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:08:54 d2.utils.events]: \u001b[0m eta: 1:55:53  iter: 1879  total_loss: 0.8916  loss_cls: 0.468  loss_box_reg: 0.3269  loss_rpn_cls: 0.02284  loss_rpn_loc: 0.0422  time: 0.5319  data_time: 0.0156  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:09:05 d2.utils.events]: \u001b[0m eta: 1:55:43  iter: 1899  total_loss: 0.8419  loss_cls: 0.4797  loss_box_reg: 0.3206  loss_rpn_cls: 0.02462  loss_rpn_loc: 0.02912  time: 0.5320  data_time: 0.0170  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:09:15 d2.utils.events]: \u001b[0m eta: 1:55:33  iter: 1919  total_loss: 0.7025  loss_cls: 0.3683  loss_box_reg: 0.2691  loss_rpn_cls: 0.01425  loss_rpn_loc: 0.01352  time: 0.5320  data_time: 0.0154  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:09:26 d2.utils.events]: \u001b[0m eta: 1:55:23  iter: 1939  total_loss: 0.8567  loss_cls: 0.4448  loss_box_reg: 0.3155  loss_rpn_cls: 0.03651  loss_rpn_loc: 0.04019  time: 0.5320  data_time: 0.0166  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:09:37 d2.utils.events]: \u001b[0m eta: 1:55:14  iter: 1959  total_loss: 0.8146  loss_cls: 0.4426  loss_box_reg: 0.2635  loss_rpn_cls: 0.0181  loss_rpn_loc: 0.02705  time: 0.5321  data_time: 0.0164  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:09:47 d2.utils.events]: \u001b[0m eta: 1:55:03  iter: 1979  total_loss: 0.7704  loss_cls: 0.4402  loss_box_reg: 0.2969  loss_rpn_cls: 0.02775  loss_rpn_loc: 0.01969  time: 0.5321  data_time: 0.0147  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:09:58 d2.utils.events]: \u001b[0m eta: 1:54:53  iter: 1999  total_loss: 0.7828  loss_cls: 0.471  loss_box_reg: 0.2946  loss_rpn_cls: 0.02522  loss_rpn_loc: 0.01898  time: 0.5320  data_time: 0.0147  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:10:08 d2.utils.events]: \u001b[0m eta: 1:54:42  iter: 2019  total_loss: 0.7452  loss_cls: 0.3853  loss_box_reg: 0.2685  loss_rpn_cls: 0.02359  loss_rpn_loc: 0.01563  time: 0.5320  data_time: 0.0148  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:10:19 d2.utils.events]: \u001b[0m eta: 1:54:31  iter: 2039  total_loss: 0.9263  loss_cls: 0.4733  loss_box_reg: 0.3031  loss_rpn_cls: 0.02424  loss_rpn_loc: 0.03872  time: 0.5320  data_time: 0.0171  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:10:30 d2.utils.events]: \u001b[0m eta: 1:54:21  iter: 2059  total_loss: 0.8833  loss_cls: 0.4632  loss_box_reg: 0.3358  loss_rpn_cls: 0.02562  loss_rpn_loc: 0.03525  time: 0.5321  data_time: 0.0159  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:10:41 d2.utils.events]: \u001b[0m eta: 1:54:11  iter: 2079  total_loss: 0.714  loss_cls: 0.3845  loss_box_reg: 0.2718  loss_rpn_cls: 0.0159  loss_rpn_loc: 0.01645  time: 0.5321  data_time: 0.0158  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:10:51 d2.utils.events]: \u001b[0m eta: 1:54:02  iter: 2099  total_loss: 0.7734  loss_cls: 0.4503  loss_box_reg: 0.2642  loss_rpn_cls: 0.01977  loss_rpn_loc: 0.01951  time: 0.5322  data_time: 0.0160  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:11:02 d2.utils.events]: \u001b[0m eta: 1:53:52  iter: 2119  total_loss: 0.8154  loss_cls: 0.4334  loss_box_reg: 0.3009  loss_rpn_cls: 0.01494  loss_rpn_loc: 0.02326  time: 0.5323  data_time: 0.0151  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:11:13 d2.utils.events]: \u001b[0m eta: 1:53:42  iter: 2139  total_loss: 0.7206  loss_cls: 0.4088  loss_box_reg: 0.2802  loss_rpn_cls: 0.01459  loss_rpn_loc: 0.02351  time: 0.5323  data_time: 0.0154  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:11:24 d2.utils.events]: \u001b[0m eta: 1:53:32  iter: 2159  total_loss: 0.8319  loss_cls: 0.4044  loss_box_reg: 0.3117  loss_rpn_cls: 0.03447  loss_rpn_loc: 0.04677  time: 0.5323  data_time: 0.0163  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:11:34 d2.utils.events]: \u001b[0m eta: 1:53:21  iter: 2179  total_loss: 0.6201  loss_cls: 0.3586  loss_box_reg: 0.2342  loss_rpn_cls: 0.01186  loss_rpn_loc: 0.01443  time: 0.5323  data_time: 0.0150  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:11:45 d2.utils.events]: \u001b[0m eta: 1:53:10  iter: 2199  total_loss: 0.773  loss_cls: 0.3767  loss_box_reg: 0.3225  loss_rpn_cls: 0.02291  loss_rpn_loc: 0.02603  time: 0.5323  data_time: 0.0155  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:11:56 d2.utils.events]: \u001b[0m eta: 1:53:01  iter: 2219  total_loss: 0.774  loss_cls: 0.4285  loss_box_reg: 0.2923  loss_rpn_cls: 0.02152  loss_rpn_loc: 0.01866  time: 0.5324  data_time: 0.0184  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:12:07 d2.utils.events]: \u001b[0m eta: 1:52:51  iter: 2239  total_loss: 0.8394  loss_cls: 0.4286  loss_box_reg: 0.3541  loss_rpn_cls: 0.0307  loss_rpn_loc: 0.0277  time: 0.5324  data_time: 0.0158  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:12:17 d2.utils.events]: \u001b[0m eta: 1:52:41  iter: 2259  total_loss: 0.6829  loss_cls: 0.4114  loss_box_reg: 0.2525  loss_rpn_cls: 0.01955  loss_rpn_loc: 0.02708  time: 0.5324  data_time: 0.0150  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:12:28 d2.utils.events]: \u001b[0m eta: 1:52:29  iter: 2279  total_loss: 0.7557  loss_cls: 0.4414  loss_box_reg: 0.2958  loss_rpn_cls: 0.015  loss_rpn_loc: 0.02005  time: 0.5323  data_time: 0.0147  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:12:38 d2.utils.events]: \u001b[0m eta: 1:52:18  iter: 2299  total_loss: 0.8052  loss_cls: 0.3652  loss_box_reg: 0.3156  loss_rpn_cls: 0.02933  loss_rpn_loc: 0.03246  time: 0.5323  data_time: 0.0148  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:12:49 d2.utils.events]: \u001b[0m eta: 1:52:07  iter: 2319  total_loss: 0.7975  loss_cls: 0.472  loss_box_reg: 0.2716  loss_rpn_cls: 0.02548  loss_rpn_loc: 0.02347  time: 0.5324  data_time: 0.0157  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:13:00 d2.utils.events]: \u001b[0m eta: 1:51:56  iter: 2339  total_loss: 0.6694  loss_cls: 0.364  loss_box_reg: 0.2378  loss_rpn_cls: 0.01585  loss_rpn_loc: 0.02163  time: 0.5324  data_time: 0.0154  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:13:11 d2.utils.events]: \u001b[0m eta: 1:51:46  iter: 2359  total_loss: 0.7506  loss_cls: 0.404  loss_box_reg: 0.2801  loss_rpn_cls: 0.02133  loss_rpn_loc: 0.01858  time: 0.5324  data_time: 0.0165  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:13:21 d2.utils.events]: \u001b[0m eta: 1:51:35  iter: 2379  total_loss: 0.7512  loss_cls: 0.3739  loss_box_reg: 0.3104  loss_rpn_cls: 0.02018  loss_rpn_loc: 0.01721  time: 0.5324  data_time: 0.0149  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:13:32 d2.utils.events]: \u001b[0m eta: 1:51:25  iter: 2399  total_loss: 0.7755  loss_cls: 0.3901  loss_box_reg: 0.322  loss_rpn_cls: 0.02445  loss_rpn_loc: 0.02821  time: 0.5325  data_time: 0.0188  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:13:43 d2.utils.events]: \u001b[0m eta: 1:51:16  iter: 2419  total_loss: 0.7783  loss_cls: 0.4067  loss_box_reg: 0.3044  loss_rpn_cls: 0.0225  loss_rpn_loc: 0.01869  time: 0.5325  data_time: 0.0157  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:13:54 d2.utils.events]: \u001b[0m eta: 1:51:06  iter: 2439  total_loss: 0.7019  loss_cls: 0.3798  loss_box_reg: 0.298  loss_rpn_cls: 0.02069  loss_rpn_loc: 0.01495  time: 0.5326  data_time: 0.0149  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:14:04 d2.utils.events]: \u001b[0m eta: 1:50:54  iter: 2459  total_loss: 0.7598  loss_cls: 0.4335  loss_box_reg: 0.2313  loss_rpn_cls: 0.02596  loss_rpn_loc: 0.02898  time: 0.5326  data_time: 0.0156  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:14:15 d2.utils.events]: \u001b[0m eta: 1:50:44  iter: 2479  total_loss: 0.7726  loss_cls: 0.4163  loss_box_reg: 0.2915  loss_rpn_cls: 0.01932  loss_rpn_loc: 0.02566  time: 0.5326  data_time: 0.0149  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:14:26 d2.utils.events]: \u001b[0m eta: 1:50:32  iter: 2499  total_loss: 0.7515  loss_cls: 0.4136  loss_box_reg: 0.26  loss_rpn_cls: 0.02102  loss_rpn_loc: 0.01968  time: 0.5326  data_time: 0.0157  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:14:36 d2.utils.events]: \u001b[0m eta: 1:50:22  iter: 2519  total_loss: 0.5939  loss_cls: 0.298  loss_box_reg: 0.233  loss_rpn_cls: 0.01677  loss_rpn_loc: 0.01949  time: 0.5326  data_time: 0.0176  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:14:47 d2.utils.events]: \u001b[0m eta: 1:50:13  iter: 2539  total_loss: 0.7756  loss_cls: 0.4466  loss_box_reg: 0.2702  loss_rpn_cls: 0.02019  loss_rpn_loc: 0.02777  time: 0.5326  data_time: 0.0151  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:14:58 d2.utils.events]: \u001b[0m eta: 1:50:03  iter: 2559  total_loss: 0.6865  loss_cls: 0.3789  loss_box_reg: 0.2727  loss_rpn_cls: 0.01603  loss_rpn_loc: 0.02645  time: 0.5326  data_time: 0.0153  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:15:08 d2.utils.events]: \u001b[0m eta: 1:49:52  iter: 2579  total_loss: 0.6408  loss_cls: 0.3433  loss_box_reg: 0.2696  loss_rpn_cls: 0.0187  loss_rpn_loc: 0.02574  time: 0.5326  data_time: 0.0147  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:15:19 d2.utils.events]: \u001b[0m eta: 1:49:42  iter: 2599  total_loss: 0.7426  loss_cls: 0.3888  loss_box_reg: 0.3023  loss_rpn_cls: 0.01875  loss_rpn_loc: 0.01906  time: 0.5326  data_time: 0.0150  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:15:30 d2.utils.events]: \u001b[0m eta: 1:49:33  iter: 2619  total_loss: 0.7371  loss_cls: 0.3737  loss_box_reg: 0.2788  loss_rpn_cls: 0.01837  loss_rpn_loc: 0.02726  time: 0.5327  data_time: 0.0174  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:15:41 d2.utils.events]: \u001b[0m eta: 1:49:23  iter: 2639  total_loss: 0.7407  loss_cls: 0.3919  loss_box_reg: 0.267  loss_rpn_cls: 0.02632  loss_rpn_loc: 0.04112  time: 0.5327  data_time: 0.0169  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:15:51 d2.utils.events]: \u001b[0m eta: 1:49:14  iter: 2659  total_loss: 0.6422  loss_cls: 0.3763  loss_box_reg: 0.2552  loss_rpn_cls: 0.02047  loss_rpn_loc: 0.01953  time: 0.5327  data_time: 0.0155  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:16:02 d2.utils.events]: \u001b[0m eta: 1:49:04  iter: 2679  total_loss: 0.6769  loss_cls: 0.3794  loss_box_reg: 0.2568  loss_rpn_cls: 0.02073  loss_rpn_loc: 0.02535  time: 0.5327  data_time: 0.0149  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:16:13 d2.utils.events]: \u001b[0m eta: 1:48:54  iter: 2699  total_loss: 0.7062  loss_cls: 0.3724  loss_box_reg: 0.2585  loss_rpn_cls: 0.02405  loss_rpn_loc: 0.02021  time: 0.5327  data_time: 0.0153  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:16:23 d2.utils.events]: \u001b[0m eta: 1:48:42  iter: 2719  total_loss: 0.711  loss_cls: 0.3563  loss_box_reg: 0.2662  loss_rpn_cls: 0.02366  loss_rpn_loc: 0.03114  time: 0.5327  data_time: 0.0157  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:16:34 d2.utils.events]: \u001b[0m eta: 1:48:30  iter: 2739  total_loss: 0.659  loss_cls: 0.3889  loss_box_reg: 0.2633  loss_rpn_cls: 0.01851  loss_rpn_loc: 0.03697  time: 0.5327  data_time: 0.0149  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:16:45 d2.utils.events]: \u001b[0m eta: 1:48:20  iter: 2759  total_loss: 0.816  loss_cls: 0.4264  loss_box_reg: 0.3048  loss_rpn_cls: 0.02354  loss_rpn_loc: 0.03442  time: 0.5327  data_time: 0.0163  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:16:55 d2.utils.events]: \u001b[0m eta: 1:48:10  iter: 2779  total_loss: 0.6696  loss_cls: 0.3551  loss_box_reg: 0.284  loss_rpn_cls: 0.01776  loss_rpn_loc: 0.0149  time: 0.5327  data_time: 0.0153  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:17:06 d2.utils.events]: \u001b[0m eta: 1:47:59  iter: 2799  total_loss: 0.6723  loss_cls: 0.3598  loss_box_reg: 0.2456  loss_rpn_cls: 0.01738  loss_rpn_loc: 0.0205  time: 0.5326  data_time: 0.0148  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:17:16 d2.utils.events]: \u001b[0m eta: 1:47:48  iter: 2819  total_loss: 0.695  loss_cls: 0.3828  loss_box_reg: 0.2512  loss_rpn_cls: 0.01343  loss_rpn_loc: 0.0184  time: 0.5326  data_time: 0.0148  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:17:27 d2.utils.events]: \u001b[0m eta: 1:47:38  iter: 2839  total_loss: 0.7052  loss_cls: 0.3698  loss_box_reg: 0.2397  loss_rpn_cls: 0.02683  loss_rpn_loc: 0.02719  time: 0.5326  data_time: 0.0149  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:17:38 d2.utils.events]: \u001b[0m eta: 1:47:28  iter: 2859  total_loss: 0.7359  loss_cls: 0.3913  loss_box_reg: 0.2599  loss_rpn_cls: 0.02267  loss_rpn_loc: 0.02916  time: 0.5326  data_time: 0.0154  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:17:48 d2.utils.events]: \u001b[0m eta: 1:47:17  iter: 2879  total_loss: 0.6723  loss_cls: 0.3745  loss_box_reg: 0.2721  loss_rpn_cls: 0.01761  loss_rpn_loc: 0.02249  time: 0.5326  data_time: 0.0156  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:17:59 d2.utils.events]: \u001b[0m eta: 1:47:05  iter: 2899  total_loss: 0.721  loss_cls: 0.4079  loss_box_reg: 0.2658  loss_rpn_cls: 0.01259  loss_rpn_loc: 0.02049  time: 0.5326  data_time: 0.0156  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:18:10 d2.utils.events]: \u001b[0m eta: 1:46:53  iter: 2919  total_loss: 0.7253  loss_cls: 0.3827  loss_box_reg: 0.3039  loss_rpn_cls: 0.02291  loss_rpn_loc: 0.02479  time: 0.5326  data_time: 0.0148  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:18:20 d2.utils.events]: \u001b[0m eta: 1:46:42  iter: 2939  total_loss: 0.6504  loss_cls: 0.3479  loss_box_reg: 0.268  loss_rpn_cls: 0.02039  loss_rpn_loc: 0.02141  time: 0.5326  data_time: 0.0147  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:18:31 d2.utils.events]: \u001b[0m eta: 1:46:31  iter: 2959  total_loss: 0.6501  loss_cls: 0.346  loss_box_reg: 0.2544  loss_rpn_cls: 0.01675  loss_rpn_loc: 0.0228  time: 0.5327  data_time: 0.0152  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:18:42 d2.utils.events]: \u001b[0m eta: 1:46:21  iter: 2979  total_loss: 0.6273  loss_cls: 0.3368  loss_box_reg: 0.2484  loss_rpn_cls: 0.01765  loss_rpn_loc: 0.02226  time: 0.5326  data_time: 0.0161  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:18:53 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ./dataset/test.json\n",
      "\u001b[32m[09/29 05:18:53 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "| General trash | 0            |    Paper    | 0            | Paper pack | 0            |\n",
      "|     Metal     | 0            |    Glass    | 0            |  Plastic   | 0            |\n",
      "|   Styrofoam   | 0            | Plastic bag | 0            |  Battery   | 0            |\n",
      "|   Clothing    | 0            |             |              |            |              |\n",
      "|     total     | 0            |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[09/29 05:18:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/29 05:18:53 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/29 05:18:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.50 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/29 05:18:53 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/29 05:18:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[09/29 05:18:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0010 s/iter. Inference: 0.0447 s/iter. Eval: 0.0002 s/iter. Total: 0.0459 s/iter. ETA=0:03:42\n",
      "\u001b[32m[09/29 05:19:02 d2.evaluation.evaluator]: \u001b[0mInference done 129/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0429 s/iter. ETA=0:03:23\n",
      "\u001b[32m[09/29 05:19:07 d2.evaluation.evaluator]: \u001b[0mInference done 246/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:03:18\n",
      "\u001b[32m[09/29 05:19:12 d2.evaluation.evaluator]: \u001b[0mInference done 360/4871. Dataloading: 0.0013 s/iter. Inference: 0.0418 s/iter. Eval: 0.0002 s/iter. Total: 0.0433 s/iter. ETA=0:03:15\n",
      "\u001b[32m[09/29 05:19:17 d2.evaluation.evaluator]: \u001b[0mInference done 477/4871. Dataloading: 0.0013 s/iter. Inference: 0.0416 s/iter. Eval: 0.0002 s/iter. Total: 0.0432 s/iter. ETA=0:03:09\n",
      "\u001b[32m[09/29 05:19:22 d2.evaluation.evaluator]: \u001b[0mInference done 591/4871. Dataloading: 0.0013 s/iter. Inference: 0.0418 s/iter. Eval: 0.0002 s/iter. Total: 0.0434 s/iter. ETA=0:03:05\n",
      "\u001b[32m[09/29 05:19:27 d2.evaluation.evaluator]: \u001b[0mInference done 709/4871. Dataloading: 0.0013 s/iter. Inference: 0.0417 s/iter. Eval: 0.0002 s/iter. Total: 0.0432 s/iter. ETA=0:02:59\n",
      "\u001b[32m[09/29 05:19:32 d2.evaluation.evaluator]: \u001b[0mInference done 827/4871. Dataloading: 0.0013 s/iter. Inference: 0.0416 s/iter. Eval: 0.0002 s/iter. Total: 0.0431 s/iter. ETA=0:02:54\n",
      "\u001b[32m[09/29 05:19:37 d2.evaluation.evaluator]: \u001b[0mInference done 945/4871. Dataloading: 0.0013 s/iter. Inference: 0.0415 s/iter. Eval: 0.0002 s/iter. Total: 0.0431 s/iter. ETA=0:02:49\n",
      "\u001b[32m[09/29 05:19:42 d2.evaluation.evaluator]: \u001b[0mInference done 1063/4871. Dataloading: 0.0012 s/iter. Inference: 0.0415 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:02:43\n",
      "\u001b[32m[09/29 05:19:47 d2.evaluation.evaluator]: \u001b[0mInference done 1181/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:02:38\n",
      "\u001b[32m[09/29 05:19:52 d2.evaluation.evaluator]: \u001b[0mInference done 1300/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0429 s/iter. ETA=0:02:33\n",
      "\u001b[32m[09/29 05:19:57 d2.evaluation.evaluator]: \u001b[0mInference done 1417/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0429 s/iter. ETA=0:02:28\n",
      "\u001b[32m[09/29 05:20:02 d2.evaluation.evaluator]: \u001b[0mInference done 1534/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0429 s/iter. ETA=0:02:23\n",
      "\u001b[32m[09/29 05:20:07 d2.evaluation.evaluator]: \u001b[0mInference done 1651/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0429 s/iter. ETA=0:02:18\n",
      "\u001b[32m[09/29 05:20:12 d2.evaluation.evaluator]: \u001b[0mInference done 1769/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0429 s/iter. ETA=0:02:13\n",
      "\u001b[32m[09/29 05:20:17 d2.evaluation.evaluator]: \u001b[0mInference done 1887/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0429 s/iter. ETA=0:02:07\n",
      "\u001b[32m[09/29 05:20:22 d2.evaluation.evaluator]: \u001b[0mInference done 2004/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0429 s/iter. ETA=0:02:02\n",
      "\u001b[32m[09/29 05:20:27 d2.evaluation.evaluator]: \u001b[0mInference done 2120/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0429 s/iter. ETA=0:01:58\n",
      "\u001b[32m[09/29 05:20:32 d2.evaluation.evaluator]: \u001b[0mInference done 2237/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0429 s/iter. ETA=0:01:53\n",
      "\u001b[32m[09/29 05:20:37 d2.evaluation.evaluator]: \u001b[0mInference done 2355/4871. Dataloading: 0.0012 s/iter. Inference: 0.0413 s/iter. Eval: 0.0002 s/iter. Total: 0.0429 s/iter. ETA=0:01:47\n",
      "\u001b[32m[09/29 05:20:42 d2.evaluation.evaluator]: \u001b[0mInference done 2470/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0429 s/iter. ETA=0:01:43\n",
      "\u001b[32m[09/29 05:20:47 d2.evaluation.evaluator]: \u001b[0mInference done 2588/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0429 s/iter. ETA=0:01:37\n",
      "\u001b[32m[09/29 05:20:52 d2.evaluation.evaluator]: \u001b[0mInference done 2705/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0429 s/iter. ETA=0:01:32\n",
      "\u001b[32m[09/29 05:20:57 d2.evaluation.evaluator]: \u001b[0mInference done 2819/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:01:28\n",
      "\u001b[32m[09/29 05:21:02 d2.evaluation.evaluator]: \u001b[0mInference done 2935/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:01:23\n",
      "\u001b[32m[09/29 05:21:07 d2.evaluation.evaluator]: \u001b[0mInference done 3053/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:01:18\n",
      "\u001b[32m[09/29 05:21:12 d2.evaluation.evaluator]: \u001b[0mInference done 3171/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0429 s/iter. ETA=0:01:13\n",
      "\u001b[32m[09/29 05:21:17 d2.evaluation.evaluator]: \u001b[0mInference done 3288/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0429 s/iter. ETA=0:01:07\n",
      "\u001b[32m[09/29 05:21:22 d2.evaluation.evaluator]: \u001b[0mInference done 3405/4871. Dataloading: 0.0012 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:01:02\n",
      "\u001b[32m[09/29 05:21:27 d2.evaluation.evaluator]: \u001b[0mInference done 3521/4871. Dataloading: 0.0013 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:00:57\n",
      "\u001b[32m[09/29 05:21:32 d2.evaluation.evaluator]: \u001b[0mInference done 3637/4871. Dataloading: 0.0013 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:00:53\n",
      "\u001b[32m[09/29 05:21:37 d2.evaluation.evaluator]: \u001b[0mInference done 3754/4871. Dataloading: 0.0013 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:00:47\n",
      "\u001b[32m[09/29 05:21:42 d2.evaluation.evaluator]: \u001b[0mInference done 3870/4871. Dataloading: 0.0013 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/29 05:21:47 d2.evaluation.evaluator]: \u001b[0mInference done 3987/4871. Dataloading: 0.0013 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:00:37\n",
      "\u001b[32m[09/29 05:21:52 d2.evaluation.evaluator]: \u001b[0mInference done 4104/4871. Dataloading: 0.0013 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:00:32\n",
      "\u001b[32m[09/29 05:21:57 d2.evaluation.evaluator]: \u001b[0mInference done 4222/4871. Dataloading: 0.0013 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:00:27\n",
      "\u001b[32m[09/29 05:22:02 d2.evaluation.evaluator]: \u001b[0mInference done 4337/4871. Dataloading: 0.0013 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:00:22\n",
      "\u001b[32m[09/29 05:22:07 d2.evaluation.evaluator]: \u001b[0mInference done 4454/4871. Dataloading: 0.0013 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:00:17\n",
      "\u001b[32m[09/29 05:22:13 d2.evaluation.evaluator]: \u001b[0mInference done 4570/4871. Dataloading: 0.0013 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:00:12\n",
      "\u001b[32m[09/29 05:22:18 d2.evaluation.evaluator]: \u001b[0mInference done 4687/4871. Dataloading: 0.0013 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/29 05:22:23 d2.evaluation.evaluator]: \u001b[0mInference done 4804/4871. Dataloading: 0.0013 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:00:02\n",
      "\u001b[32m[09/29 05:22:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:29.257053 (0.043004 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/29 05:22:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:21 (0.041427 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/29 05:22:26 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/29 05:22:26 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[09/29 05:22:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.55s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/29 05:22:28 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/29 05:22:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.26 seconds.\n",
      "\u001b[32m[09/29 05:22:30 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/29 05:22:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.23 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[09/29 05:22:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP  |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| nan  |  nan   |  nan   |  nan  |  nan  |  nan  |\n",
      "\u001b[32m[09/29 05:22:30 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/29 05:22:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP   | category    | AP   | category   | AP   |\n",
      "|:--------------|:-----|:------------|:-----|:-----------|:-----|\n",
      "| General trash | nan  | Paper       | nan  | Paper pack | nan  |\n",
      "| Metal         | nan  | Glass       | nan  | Plastic    | nan  |\n",
      "| Styrofoam     | nan  | Plastic bag | nan  | Battery    | nan  |\n",
      "| Clothing      | nan  |             |      |            |      |\n",
      "\u001b[32m[09/29 05:22:30 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[09/29 05:22:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/29 05:22:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/29 05:22:30 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
      "\u001b[32m[09/29 05:22:30 d2.utils.events]: \u001b[0m eta: 1:46:11  iter: 2999  total_loss: 0.5684  loss_cls: 0.2739  loss_box_reg: 0.1955  loss_rpn_cls: 0.02007  loss_rpn_loc: 0.02264  time: 0.5326  data_time: 0.0158  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:22:41 d2.utils.events]: \u001b[0m eta: 1:46:01  iter: 3019  total_loss: 0.6595  loss_cls: 0.3475  loss_box_reg: 0.2495  loss_rpn_cls: 0.0171  loss_rpn_loc: 0.02546  time: 0.5326  data_time: 0.0152  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:22:52 d2.utils.events]: \u001b[0m eta: 1:45:49  iter: 3039  total_loss: 0.8706  loss_cls: 0.4606  loss_box_reg: 0.3063  loss_rpn_cls: 0.02292  loss_rpn_loc: 0.0281  time: 0.5326  data_time: 0.0150  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:23:02 d2.utils.events]: \u001b[0m eta: 1:45:38  iter: 3059  total_loss: 0.7575  loss_cls: 0.3962  loss_box_reg: 0.295  loss_rpn_cls: 0.02164  loss_rpn_loc: 0.02852  time: 0.5326  data_time: 0.0158  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:23:13 d2.utils.events]: \u001b[0m eta: 1:45:27  iter: 3079  total_loss: 0.6641  loss_cls: 0.3554  loss_box_reg: 0.2589  loss_rpn_cls: 0.02186  loss_rpn_loc: 0.01834  time: 0.5326  data_time: 0.0155  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:23:24 d2.utils.events]: \u001b[0m eta: 1:45:16  iter: 3099  total_loss: 0.756  loss_cls: 0.3823  loss_box_reg: 0.2859  loss_rpn_cls: 0.01788  loss_rpn_loc: 0.02467  time: 0.5326  data_time: 0.0153  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:23:34 d2.utils.events]: \u001b[0m eta: 1:45:04  iter: 3119  total_loss: 0.7431  loss_cls: 0.3831  loss_box_reg: 0.3162  loss_rpn_cls: 0.01462  loss_rpn_loc: 0.02833  time: 0.5326  data_time: 0.0146  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:23:45 d2.utils.events]: \u001b[0m eta: 1:44:54  iter: 3139  total_loss: 0.7019  loss_cls: 0.3966  loss_box_reg: 0.2483  loss_rpn_cls: 0.01608  loss_rpn_loc: 0.02283  time: 0.5327  data_time: 0.0153  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:23:56 d2.utils.events]: \u001b[0m eta: 1:44:43  iter: 3159  total_loss: 0.5686  loss_cls: 0.3797  loss_box_reg: 0.1911  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.02033  time: 0.5327  data_time: 0.0149  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:24:06 d2.utils.events]: \u001b[0m eta: 1:44:33  iter: 3179  total_loss: 0.6536  loss_cls: 0.323  loss_box_reg: 0.2747  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.03761  time: 0.5327  data_time: 0.0153  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:24:17 d2.utils.events]: \u001b[0m eta: 1:44:23  iter: 3199  total_loss: 0.7075  loss_cls: 0.3593  loss_box_reg: 0.2563  loss_rpn_cls: 0.01463  loss_rpn_loc: 0.01512  time: 0.5327  data_time: 0.0159  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:24:28 d2.utils.events]: \u001b[0m eta: 1:44:12  iter: 3219  total_loss: 0.6132  loss_cls: 0.3598  loss_box_reg: 0.2003  loss_rpn_cls: 0.01414  loss_rpn_loc: 0.02206  time: 0.5328  data_time: 0.0181  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:24:39 d2.utils.events]: \u001b[0m eta: 1:44:02  iter: 3239  total_loss: 0.672  loss_cls: 0.3324  loss_box_reg: 0.2721  loss_rpn_cls: 0.02469  loss_rpn_loc: 0.04323  time: 0.5328  data_time: 0.0161  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:24:50 d2.utils.events]: \u001b[0m eta: 1:43:52  iter: 3259  total_loss: 0.7412  loss_cls: 0.3709  loss_box_reg: 0.2794  loss_rpn_cls: 0.02046  loss_rpn_loc: 0.01821  time: 0.5328  data_time: 0.0154  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:25:00 d2.utils.events]: \u001b[0m eta: 1:43:42  iter: 3279  total_loss: 0.6677  loss_cls: 0.3913  loss_box_reg: 0.2087  loss_rpn_cls: 0.01646  loss_rpn_loc: 0.01471  time: 0.5328  data_time: 0.0156  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:25:11 d2.utils.events]: \u001b[0m eta: 1:43:32  iter: 3299  total_loss: 0.8681  loss_cls: 0.4565  loss_box_reg: 0.315  loss_rpn_cls: 0.02991  loss_rpn_loc: 0.03461  time: 0.5329  data_time: 0.0151  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:25:22 d2.utils.events]: \u001b[0m eta: 1:43:21  iter: 3319  total_loss: 0.6412  loss_cls: 0.3756  loss_box_reg: 0.2557  loss_rpn_cls: 0.01898  loss_rpn_loc: 0.01576  time: 0.5329  data_time: 0.0153  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:25:33 d2.utils.events]: \u001b[0m eta: 1:43:12  iter: 3339  total_loss: 0.7288  loss_cls: 0.4031  loss_box_reg: 0.2848  loss_rpn_cls: 0.0259  loss_rpn_loc: 0.02877  time: 0.5329  data_time: 0.0179  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:25:44 d2.utils.events]: \u001b[0m eta: 1:43:02  iter: 3359  total_loss: 0.7307  loss_cls: 0.4034  loss_box_reg: 0.2719  loss_rpn_cls: 0.02028  loss_rpn_loc: 0.02509  time: 0.5329  data_time: 0.0154  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:25:54 d2.utils.events]: \u001b[0m eta: 1:42:52  iter: 3379  total_loss: 0.7042  loss_cls: 0.3691  loss_box_reg: 0.2829  loss_rpn_cls: 0.01685  loss_rpn_loc: 0.03229  time: 0.5330  data_time: 0.0183  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:26:05 d2.utils.events]: \u001b[0m eta: 1:42:40  iter: 3399  total_loss: 0.7773  loss_cls: 0.371  loss_box_reg: 0.2832  loss_rpn_cls: 0.01896  loss_rpn_loc: 0.02809  time: 0.5330  data_time: 0.0151  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:26:16 d2.utils.events]: \u001b[0m eta: 1:42:29  iter: 3419  total_loss: 0.8608  loss_cls: 0.4044  loss_box_reg: 0.3558  loss_rpn_cls: 0.02893  loss_rpn_loc: 0.04418  time: 0.5330  data_time: 0.0150  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:26:26 d2.utils.events]: \u001b[0m eta: 1:42:19  iter: 3439  total_loss: 0.7226  loss_cls: 0.3796  loss_box_reg: 0.302  loss_rpn_cls: 0.01922  loss_rpn_loc: 0.03001  time: 0.5330  data_time: 0.0178  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:26:37 d2.utils.events]: \u001b[0m eta: 1:42:08  iter: 3459  total_loss: 0.6606  loss_cls: 0.376  loss_box_reg: 0.2574  loss_rpn_cls: 0.02703  loss_rpn_loc: 0.02784  time: 0.5330  data_time: 0.0163  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:26:48 d2.utils.events]: \u001b[0m eta: 1:41:58  iter: 3479  total_loss: 0.6473  loss_cls: 0.3847  loss_box_reg: 0.2264  loss_rpn_cls: 0.01413  loss_rpn_loc: 0.01534  time: 0.5331  data_time: 0.0169  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:26:59 d2.utils.events]: \u001b[0m eta: 1:41:48  iter: 3499  total_loss: 0.7681  loss_cls: 0.4058  loss_box_reg: 0.2738  loss_rpn_cls: 0.03245  loss_rpn_loc: 0.03231  time: 0.5331  data_time: 0.0156  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:27:10 d2.utils.events]: \u001b[0m eta: 1:41:38  iter: 3519  total_loss: 0.6272  loss_cls: 0.4102  loss_box_reg: 0.2454  loss_rpn_cls: 0.01382  loss_rpn_loc: 0.01436  time: 0.5332  data_time: 0.0159  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:27:20 d2.utils.events]: \u001b[0m eta: 1:41:27  iter: 3539  total_loss: 0.7112  loss_cls: 0.3766  loss_box_reg: 0.262  loss_rpn_cls: 0.01918  loss_rpn_loc: 0.02648  time: 0.5332  data_time: 0.0155  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:27:31 d2.utils.events]: \u001b[0m eta: 1:41:17  iter: 3559  total_loss: 0.7689  loss_cls: 0.3916  loss_box_reg: 0.2681  loss_rpn_cls: 0.02232  loss_rpn_loc: 0.02653  time: 0.5332  data_time: 0.0160  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:27:42 d2.utils.events]: \u001b[0m eta: 1:41:07  iter: 3579  total_loss: 0.7135  loss_cls: 0.3472  loss_box_reg: 0.2603  loss_rpn_cls: 0.01811  loss_rpn_loc: 0.02399  time: 0.5332  data_time: 0.0176  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:27:53 d2.utils.events]: \u001b[0m eta: 1:40:56  iter: 3599  total_loss: 0.6192  loss_cls: 0.3095  loss_box_reg: 0.2214  loss_rpn_cls: 0.0138  loss_rpn_loc: 0.0141  time: 0.5332  data_time: 0.0164  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:28:03 d2.utils.events]: \u001b[0m eta: 1:40:45  iter: 3619  total_loss: 0.7092  loss_cls: 0.3969  loss_box_reg: 0.2675  loss_rpn_cls: 0.01465  loss_rpn_loc: 0.0199  time: 0.5332  data_time: 0.0169  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:28:14 d2.utils.events]: \u001b[0m eta: 1:40:34  iter: 3639  total_loss: 0.6843  loss_cls: 0.37  loss_box_reg: 0.2612  loss_rpn_cls: 0.01696  loss_rpn_loc: 0.03509  time: 0.5332  data_time: 0.0152  lr: 0.001  max_mem: 20741M\n",
      "\u001b[32m[09/29 05:28:25 d2.utils.events]: \u001b[0m eta: 1:40:23  iter: 3659  total_loss: 0.7496  loss_cls: 0.4144  loss_box_reg: 0.2501  loss_rpn_cls: 0.01775  loss_rpn_loc: 0.01634  time: 0.5332  data_time: 0.0149  lr: 0.001  max_mem: 20741M\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}