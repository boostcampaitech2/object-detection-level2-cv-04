{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 810
    },
    "id": "O_tnPGK74wUM",
    "outputId": "c6e7e511-cd30-4b08-ec0f-76be2eeb609d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: effdet in /opt/conda/envs/detection/lib/python3.7/site-packages (0.2.4)\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/envs/detection/lib/python3.7/site-packages (from effdet) (1.7.1)\n",
      "Requirement already satisfied: timm>=0.3.2 in /opt/conda/envs/detection/lib/python3.7/site-packages (from effdet) (0.4.12)\n",
      "Requirement already satisfied: omegaconf>=2.0 in /opt/conda/envs/detection/lib/python3.7/site-packages (from effdet) (2.1.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/envs/detection/lib/python3.7/site-packages (from effdet) (0.8.2)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /opt/conda/envs/detection/lib/python3.7/site-packages (from effdet) (2.0.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /opt/conda/envs/detection/lib/python3.7/site-packages (from omegaconf>=2.0->effdet) (4.8)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /opt/conda/envs/detection/lib/python3.7/site-packages (from omegaconf>=2.0->effdet) (5.4.1)\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/envs/detection/lib/python3.7/site-packages (from pycocotools>=2.0.2->effdet) (58.0.4)\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/envs/detection/lib/python3.7/site-packages (from pycocotools>=2.0.2->effdet) (0.29.24)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/envs/detection/lib/python3.7/site-packages (from pycocotools>=2.0.2->effdet) (3.4.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/detection/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/envs/detection/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet) (8.3.1)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/envs/detection/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/detection/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/envs/detection/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/detection/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet) (0.10.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/detection/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools>=2.0.2->effdet) (1.16.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/envs/detection/lib/python3.7/site-packages (from torch>=1.4->effdet) (3.10.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install effdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "n5QtMnjy4g2y"
   },
   "outputs": [],
   "source": [
    "# 라이브러리 및 모듈 import\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain\n",
    "from effdet.efficientdet import HeadNet\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Xu7QfZ-14g28"
   },
   "outputs": [],
   "source": [
    "# CustomDataset class 선언\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    '''\n",
    "      data_dir: data가 존재하는 폴더 경로\n",
    "      transforms: data transform (resize, crop, Totensor, etc,,,)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, annotation, data_dir, transforms=None):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "        # coco annotation 불러오기 (by. coco API)\n",
    "        self.coco = COCO(annotation)\n",
    "        self.predictions = {\n",
    "            \"images\": self.coco.dataset[\"images\"].copy(),\n",
    "            \"categories\": self.coco.dataset[\"categories\"].copy(),\n",
    "            \"annotations\": None\n",
    "        }\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "\n",
    "        image_info = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        image = cv2.imread(os.path.join(self.data_dir, image_info['file_name']))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=image_info['id'])\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "        # boxes (x, y, w, h)\n",
    "        boxes = np.array([x['bbox'] for x in anns])\n",
    "\n",
    "        # boxex (x_min, y_min, x_max, y_max)\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "        \n",
    "        # box별 label\n",
    "        labels = np.array([x['category_id'] for x in anns])\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        areas = np.array([x['area'] for x in anns])\n",
    "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
    "        \n",
    "        is_crowds = np.array([x['iscrowd'] for x in anns])\n",
    "        is_crowds = torch.as_tensor(is_crowds, dtype=torch.int64)\n",
    "\n",
    "        target = {'boxes': boxes, 'labels': labels, 'image_id': torch.tensor([index]), 'area': areas,\n",
    "                  'iscrowd': is_crowds}\n",
    "\n",
    "        # transform\n",
    "        if self.transforms:\n",
    "            while True:\n",
    "                sample = self.transforms(**{\n",
    "                    'image': image,\n",
    "                    'bboxes': target['boxes'],\n",
    "                    'labels': labels\n",
    "                })\n",
    "                if len(sample['bboxes']) > 0:\n",
    "                    image = sample['image']\n",
    "                    target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "                    target['boxes'][:,[0,1,2,3]] = target['boxes'][:,[1,0,3,2]]  #yxyx: be warning\n",
    "                    target['labels'] = torch.tensor(sample['labels'])\n",
    "                    break\n",
    "            \n",
    "        return image, target, image_id\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "k_mYQSta4g2_"
   },
   "outputs": [],
   "source": [
    "# Albumentation을 이용, augmentation 선언\n",
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        A.Resize(512, 512),\n",
    "        A.Flip(p=0.5),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "\n",
    "def get_valid_transform():\n",
    "    return A.Compose([\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Lx1ih23h4g3C"
   },
   "outputs": [],
   "source": [
    "# loss 추적\n",
    "class Averager:\n",
    "    def __init__(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "    def send(self, value):\n",
    "        self.current_total += value\n",
    "        self.iterations += 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        if self.iterations == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.0 * self.current_total / self.iterations\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ERF2BAfo4g3D"
   },
   "outputs": [],
   "source": [
    "# Effdet config\n",
    "# https://github.com/rwightman/efficientdet-pytorch/blob/master/effdet/config/model_config.py\n",
    "\n",
    "# Effdet config를 통해 모델 불러오기\n",
    "def get_net(checkpoint_path=None):\n",
    "    \n",
    "    config = get_efficientdet_config('tf_efficientdet_d3')\n",
    "    config.num_classes = 10\n",
    "    config.image_size = (512,512)\n",
    "    \n",
    "    config.soft_nms = False # 겹쳐있는 이미지가 많으므로 적용해야하나?\n",
    "    config.max_det_per_image = 25\n",
    "    \n",
    "    net = EfficientDet(config, pretrained_backbone=True)\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes)\n",
    "    \n",
    "    if checkpoint_path:\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        net.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "    return DetBenchTrain(net)\n",
    "    \n",
    "# train function\n",
    "def train_fn(num_epochs, train_data_loader, optimizer, model, device, clip=35):\n",
    "    loss_hist = Averager()\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        loss_hist.reset()\n",
    "        \n",
    "        for images, targets, image_ids in tqdm(train_data_loader):\n",
    "            \n",
    "                images = torch.stack(images) # bs, ch, w, h - 16, 3, 1024, 1024 # 1024로 늘어났겠제\n",
    "                images = images.to(device).float()\n",
    "                boxes = [target['boxes'].to(device).float() for target in targets]\n",
    "                labels = [target['labels'].to(device).float() for target in targets]\n",
    "                target = {\"bbox\": boxes, \"cls\": labels}\n",
    "\n",
    "                # calculate loss\n",
    "                loss, cls_loss, box_loss = model(images, target).values()\n",
    "                loss_value = loss.detach().item()\n",
    "                \n",
    "                loss_hist.send(loss_value)\n",
    "                \n",
    "                # backward\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # grad clip\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                \n",
    "                optimizer.step()\n",
    "\n",
    "        print(f\"Epoch #{epoch+1} loss: {loss_hist.value}\")\n",
    "        torch.save(model.state_dict(), f'epoch_{epoch+1}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0mbJK-ae4g3E"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    annotation = '../../dataset/train.json'\n",
    "    data_dir = '../../dataset'\n",
    "    train_dataset = CustomDataset(annotation, data_dir, get_train_transform())\n",
    "    \n",
    "    train_data_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=8,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    print(device)\n",
    "\n",
    "    model = get_net()\n",
    "    model.to(device)\n",
    "    \n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005) # momentum?\n",
    "\n",
    "    num_epochs = 50\n",
    "\n",
    "    loss = train_fn(num_epochs, train_data_loader, optimizer, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UuCiT5tZ4g3G",
    "outputId": "cb631ed3-95a0-4d9b-e0ac-c2a6e45c33a5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:29<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1 loss: 12.902541795846092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:30<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2 loss: 1.1272291992768133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:28<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3 loss: 1.003897368517718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:28<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4 loss: 0.9223670079548113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:26<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5 loss: 0.8665989498850172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:29<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6 loss: 0.8192975086978531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:28<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7 loss: 0.7800591438277068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:26<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8 loss: 0.750369444318762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:25<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9 loss: 0.7244996253382749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:27<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10 loss: 0.7009311128169933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:27<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #11 loss: 0.6830527640013375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:26<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #12 loss: 0.6592977048917605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:27<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #13 loss: 0.6416500835586492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:25<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #14 loss: 0.6240253966978451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:26<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #15 loss: 0.6093076171929629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:29<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #16 loss: 0.5913497242229074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:25<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #17 loss: 0.578960852029866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:26<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #18 loss: 0.5629986698225555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:28<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #19 loss: 0.547837249727374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 455/611 [03:17<01:07,  2.32it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 611/611 [04:26<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #31 loss: 0.43440149105024417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:27<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #32 loss: 0.42164254627524345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:28<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #33 loss: 0.4221575116760017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:26<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #34 loss: 0.41592411684716785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:28<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #35 loss: 0.4084473759813902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 251/611 [01:50<02:33,  2.35it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 611/611 [04:26<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #47 loss: 0.3609429472743392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:26<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #48 loss: 0.3629317990642913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:28<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #49 loss: 0.3615952018532542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [04:28<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #50 loss: 0.35919399518037975\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EfficientDet_train.ipynb의 사본",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
